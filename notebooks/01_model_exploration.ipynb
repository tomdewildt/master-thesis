{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e69bd2ff-ed57-4599-bedc-27e7345b58c8",
   "metadata": {},
   "source": [
    "# 1. Model Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f3ddfd9-1c58-438a-9200-4ed7b49874eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-30 00:42:02.647233: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-30 00:42:03.195733: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from master_thesis import ModelFactory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d42af7b-eab0-46ca-bc8b-d9646ba45285",
   "metadata": {},
   "source": [
    "## 1.1 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9abc9642-102a-40b6-ad7a-7a5b2629ddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = ModelFactory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54436964-fab0-494e-a033-8c48926fb68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anthropic/claude-v1',\n",
       " 'anthropic/claude-v1-100k',\n",
       " 'anthropic/claude-instant-v1',\n",
       " 'anthropic/claude-instant-v1-100k',\n",
       " 'google/text-bison-001',\n",
       " 'google/chat-bison-001',\n",
       " 'openai/gpt2',\n",
       " 'bigscience/bloom-560m',\n",
       " 'bigscience/bloom-1b1',\n",
       " 'bigscience/bloom-1b7',\n",
       " 'bigscience/bloom-3b',\n",
       " 'bigscience/bloom-7b1',\n",
       " 'bigscience/bloom',\n",
       " 'bigscience/bloomz-560m',\n",
       " 'bigscience/bloomz-1b1',\n",
       " 'bigscience/bloomz-1b7',\n",
       " 'bigscience/bloomz-3b',\n",
       " 'bigscience/bloomz-7b1',\n",
       " 'bigscience/bloomz',\n",
       " 'facebook/xglm-564M',\n",
       " 'facebook/xglm-1.7B',\n",
       " 'facebook/xglm-2.9B',\n",
       " 'facebook/xglm-4.5B',\n",
       " 'facebook/xglm-7.5B',\n",
       " 'meta-llama/Llama-2-7b-hf',\n",
       " 'meta-llama/Llama-2-7b-chat-hf',\n",
       " 'meta-llama/Llama-2-13b-hf',\n",
       " 'meta-llama/Llama-2-13b-chat-hf',\n",
       " 'meta-llama/Llama-2-70b-hf',\n",
       " 'meta-llama/Llama-2-70b-chat-hf',\n",
       " 'google/t5-small',\n",
       " 'google/t5-base',\n",
       " 'google/t5-large',\n",
       " 'google/t5-3b',\n",
       " 'google/t5-11b',\n",
       " 'google/flan-t5-small',\n",
       " 'google/flan-t5-base',\n",
       " 'google/flan-t5-large',\n",
       " 'google/flan-t5-xl',\n",
       " 'google/flan-t5-xxl',\n",
       " 'openai/gpt-4',\n",
       " 'openai/gpt-3.5-turbo',\n",
       " 'openai/text-davinci-003',\n",
       " 'openai/text-curie-001',\n",
       " 'openai/text-babbage-001',\n",
       " 'openai/text-ada-001']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factory.list_models()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a353cda7-1a96-436b-841f-f469e18b79b7",
   "metadata": {},
   "source": [
    "## 1.2 Evaluate Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6448ea5a-523e-4d50-a633-5f149ed26258",
   "metadata": {},
   "source": [
    "### 1.2.1 Anthropic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1f2ef80-9b68-4b80-a30c-bab238520924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' A. The first letter of the alphabet is A.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = factory.get_model(\"anthropic/claude-instant-v1\")\n",
    "model.generate(\"Question: What is the first letter of the alphabet?\\nAnswer: \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0214dd84-db70-48ed-96ea-ee1adf8fbc13",
   "metadata": {},
   "source": [
    "### 1.2.2 Google Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92943c0-b6e4-4832-b77c-da30b19d04b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a95415f-5207-47db-8e2e-8524d2e78353",
   "metadata": {},
   "source": [
    "### 1.2.3 HuggingFace Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c379bbd7-9854-45b7-82a3-fdedafab0bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomdewildt/Projects/master-thesis/venv/lib/python3.11/site-packages/transformers/modeling_utils.py:2193: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/tomdewildt/Projects/master-thesis/venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1714: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\xa0If you have a baby and you can't read, the first letter of the alphabet is the letter you are asking for. \\xa0If you can't read, then you can't do it. \\xa0If you are the only person with this, then you should have an idea of what you can do. \\xa0If you can't read, then you can't do it. \\xa0If you need to read, please contact me. \\xa0If you don't know, please try to read it. \\xa0Thank you for your time. \\xa0I can't promise anything, nor am I able to give you any information, so please don't ask. \\xa0It may take a while, but it is very important.\\nPosted by: Paul M. at 6:23 PM\\nI've decided that this is a great, great idea to try and do something with the alphabet. \\xa0I think that I would like to give a little bit of thought to this idea in my comments and also on my blog. \\xa0\\nI don't know what kind of work will be done with this idea, but I will be working on it for awhile. \\xa0I'm not sure what I'll do with the first letter of the alphabet,\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = factory.get_model(\"openai/gpt2\")\n",
    "model.generate(\"Question: What is the first letter of the alphabet?\\nAnswer: \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7c61b1e-5b3b-472b-a190-31b6f7a1317a",
   "metadata": {},
   "source": [
    "### 1.2.4 OpenAI Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb2dc137-acf7-4be8-9e80-9d424fa4bafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' A'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = factory.get_model(\"openai/text-davinci-003\")\n",
    "model.generate(\"Question: What is the first letter of the alphabet?\\nAnswer: \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
